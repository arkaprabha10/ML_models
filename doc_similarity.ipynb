{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "doc_similarity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMw0H1p+uAdQAgziR/dgJWN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkaprabha10/ML_models/blob/master/doc_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5DXq5uBtvzv"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.corpus import wordnet\r\n",
        "import nltk\r\n",
        "import re\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "from sklearn.metrics.pairwise import euclidean_distances\r\n",
        "from sklearn.metrics import jaccard_similarity_score\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \r\n",
        "from sentence_transformers import SentenceTransformer\r\n",
        "from scipy.spatial import distance\r\n",
        "from nltk.corpus import stopwords\r\n",
        "import re\r\n",
        "!pip install language_tool_python\r\n",
        "import language_tool_python\r\n",
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMmf18-qxLgC"
      },
      "source": [
        "documents=['I am a good boy','He is a bad man','Being a good boy doesnt matter in todays world','Cars sucks lamborgini the best']\r\n",
        "# cleaned = [[re.sub(r'[^A-Za-z0-9]+', ' ', item) for item in inner_list] for inner_list in issue]\r\n",
        "documents_df=pd.DataFrame(documents,columns=['documents'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ADutZ0SHegq"
      },
      "source": [
        "tool = language_tool_python.LanguageTool('en-US')\r\n",
        "# use tokenizer only for cosine similarity\r\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw4StsI4Cirh"
      },
      "source": [
        "def jaccard_similarity(list1, list2):\r\n",
        "    s1 = set(list1)\r\n",
        "    s2 = set(list2)\r\n",
        "    return float(len(s1.intersection(s2)) / len(s1.union(s2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ1TafNPE9F2"
      },
      "source": [
        "def synonym_similarity(list1,list2):\r\n",
        "  for i in list1:\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GorTeN_oxrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a176a81-ba35-4ef2-e1ec-3164ed0ff816"
      },
      "source": [
        "document_embeddings = sbert_model.encode(documents_df['documents'])\r\n",
        "correct = document_embeddings[0]\r\n",
        "sample1= document_embeddings[1]\r\n",
        "sample1= document_embeddings[2]\r\n",
        "\r\n",
        "# cosine similarity\r\n",
        "c = distance.cosine(correct,sample1)\r\n",
        "a = (documents[0].split())\r\n",
        "b = (documents[1].split())\r\n",
        "\r\n",
        "# jaccard similarity\r\n",
        "j = jaccard_similarity(a,b)\r\n",
        "\r\n",
        "# grammar check\r\n",
        "matches = tool.check(documents[3])\r\n",
        "grammar_score = max(0,1 - len(matches)/len(documents[0]))\r\n",
        "print(grammar_score)\r\n",
        "print(c,j)\r\n",
        "\r\n",
        "# most_similar(0,pairwise_similarities,'Cosine Similarity')\r\n",
        "# most_similar(0,pairwise_differences,'Euclidean Distance')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8666666666666667\n",
            "0.49334603548049927 0.1111111111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bgBoLmIuQpN"
      },
      "source": [
        "def most_similar(doc_id,similarity_matrix,matrix):\r\n",
        "    print (f'Document: {documents_df.iloc[doc_id][\"documents\"]}')\r\n",
        "    print ('\\n')\r\n",
        "    print (f'Similar Documents using {matrix}:')\r\n",
        "    if matrix=='Cosine Similarity':\r\n",
        "        similar_ix=np.argsort(similarity_matrix[doc_id])[::-1]\r\n",
        "    elif matrix=='Euclidean Distance':\r\n",
        "        similar_ix=np.argsort(similarity_matrix[doc_id])\r\n",
        "    for ix in similar_ix:\r\n",
        "        if ix==doc_id:\r\n",
        "            continue\r\n",
        "        print('\\n')\r\n",
        "        print (f'Document: {documents_df.iloc[ix][\"documents\"]}')\r\n",
        "        print (f'{matrix} : {similarity_matrix[doc_id][ix]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4wOUPrBLUtw",
        "outputId": "5a4eb4c4-a02c-4980-b3ad-2c9ba6fdc16a"
      },
      "source": [
        "text = [\"this is a sentence\", \"so is this one\",\"\"]\r\n",
        "bigrams = [b for l in text for b in zip(l.split(\" \")[:-1], l.split(\" \")[1:])]\r\n",
        "print(bigrams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('this', 'is'), ('is', 'a'), ('a', 'sentence'), ('so', 'is'), ('is', 'this'), ('this', 'one')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}